{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7F2qOiE0-bty",
        "outputId": "bb10b61c-b585-45ab-a945-bcac898044f9"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 21\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     classification_report,\n\u001b[0;32m     10\u001b[0m     confusion_matrix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     ConfusionMatrixDisplay\n\u001b[0;32m     19\u001b[0m )\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 1. CONFIGURAÇÕES\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "# LSTM Autoencoder + VAE para detecção de anomalias em séries temporais\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        "    precision_recall_curve,\n",
        "    auc,\n",
        "    roc_curve,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# 1. CONFIGURAÇÕES\n",
        "\n",
        "DATA_PATH = \"segments.csv\"\n",
        "CANAL_ESCOLHIDO = \"CADC0872\"\n",
        "SEQ_LEN = 60\n",
        "LATENT_DIM = 16\n",
        "\n",
        "EPOCHS_LSTM = 60\n",
        "EPOCHS_VAE  = 60\n",
        "BATCH_SIZE  = 128\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "# 2. CARREGAR E PRÉ-PROCESSAR OS DADOS\n",
        "\n",
        "segments = pd.read_csv(DATA_PATH)\n",
        "\n",
        "segments[\"timestamp\"] = pd.to_datetime(segments[\"timestamp\"])\n",
        "segments = segments.sort_values([\"channel\", \"segment\", \"timestamp\"])\n",
        "\n",
        "print(\"Colunas do dataset:\", segments.columns.tolist())\n",
        "print(\"Exemplo de linhas:\")\n",
        "print(segments.head())\n",
        "\n",
        "# Treino normal\n",
        "train_normal = segments[\n",
        "    (segments[\"train\"] == 1) &\n",
        "    (segments[\"anomaly\"] == 0) &\n",
        "    (segments[\"channel\"] == CANAL_ESCOLHIDO)\n",
        "].copy()\n",
        "\n",
        "# Teste (normais + anômalos)\n",
        "test_data = segments[\n",
        "    (segments[\"train\"] == 0) &\n",
        "    (segments[\"channel\"] == CANAL_ESCOLHIDO)\n",
        "].copy()\n",
        "\n",
        "print(\"\\nTamanho treino normal:\", len(train_normal))\n",
        "print(\"Tamanho teste (com e sem anomalia):\", len(test_data))\n",
        "\n",
        "# Normalização\n",
        "scaler = StandardScaler()\n",
        "train_values = train_normal[[\"value\"]].values\n",
        "scaler.fit(train_values)\n",
        "\n",
        "train_normal[\"value_norm\"] = scaler.transform(train_values)\n",
        "test_data[\"value_norm\"] = scaler.transform(test_data[[\"value\"]].values)\n",
        "\n",
        "# 3. CRIAÇÃO DAS SEQUÊNCIAS (JANELAS)\n",
        "\n",
        "def create_sequences_by_segment(df, seq_len, col=\"value_norm\"):\n",
        "    \"\"\"\n",
        "    Cria sequências de tamanho seq_len em cada segmento (sem rótulo).\n",
        "    \"\"\"\n",
        "    sequences = []\n",
        "    for seg_id, df_seg in df.groupby(\"segment\"):\n",
        "        vals = df_seg[col].values\n",
        "        if len(vals) < seq_len:\n",
        "            continue\n",
        "        for i in range(len(vals) - seq_len + 1):\n",
        "            seq = vals[i:i+seq_len]\n",
        "            sequences.append(seq)\n",
        "    return np.array(sequences)\n",
        "\n",
        "\n",
        "def create_sequences_and_labels_by_segment(df, seq_len,\n",
        "                                           col=\"value_norm\",\n",
        "                                           label_col=\"anomaly\"):\n",
        "    \"\"\"\n",
        "    Cria sequências + rótulos.\n",
        "    Janela é rotulada como 1 se qualquer ponto tiver anomaly == 1.\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    for seg_id, df_seg in df.groupby(\"segment\"):\n",
        "        vals = df_seg[col].values\n",
        "        labels = df_seg[label_col].values\n",
        "        if len(vals) < seq_len:\n",
        "            continue\n",
        "        for i in range(len(vals) - seq_len + 1):\n",
        "            seq = vals[i:i+seq_len]\n",
        "            lbl_window = labels[i:i+seq_len]\n",
        "            X.append(seq)\n",
        "            y.append(1 if np.any(lbl_window == 1) else 0)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "# Gera X_train, X_test, y_test\n",
        "X_train = create_sequences_by_segment(train_normal, SEQ_LEN, col=\"value_norm\")\n",
        "X_test, y_test = create_sequences_and_labels_by_segment(\n",
        "    test_data, SEQ_LEN, col=\"value_norm\", label_col=\"anomaly\"\n",
        ")\n",
        "\n",
        "# Adiciona dimensão de features\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_test  = X_test[..., np.newaxis]\n",
        "\n",
        "print(\"\\nShape X_train:\", X_train.shape)\n",
        "print(\"Shape X_test:\", X_test.shape)\n",
        "print(\"Distribuição de y_test:\", np.bincount(y_test))\n",
        "\n",
        "timesteps = X_train.shape[1]\n",
        "n_features = X_train.shape[2]\n",
        "\n",
        "# 4. FUNÇÕES AUXILIARES (MSE, THRESHOLD, PLOTS)\n",
        "\n",
        "def reconstruction_mse(model, X):\n",
        "    \"\"\"\n",
        "    Retorna MSE de reconstrução por janela: vetor shape (n_amostras,).\n",
        "    \"\"\"\n",
        "    X_pred = model.predict(X, verbose=0)\n",
        "    mse = np.mean(np.mean(np.square(X - X_pred), axis=2), axis=1)\n",
        "    return mse\n",
        "\n",
        "\n",
        "def otimizar_threshold(train_mse, test_mse, y_test,\n",
        "                       q_low=0.90, q_high=0.999, n_thresholds=50):\n",
        "    \"\"\"\n",
        "    Busca thresholds entre os quantis q_low e q_high do MSE de treino.\n",
        "    Otimiza F1 da classe 1.\n",
        "    \"\"\"\n",
        "    q_low_val = np.quantile(train_mse, q_low)\n",
        "    q_high_val = np.quantile(train_mse, q_high)\n",
        "\n",
        "    thresholds = np.linspace(q_low_val, q_high_val, n_thresholds)\n",
        "\n",
        "    best = {\n",
        "        \"threshold\": None,\n",
        "        \"f1\": -1.0,\n",
        "        \"precision\": None,\n",
        "        \"recall\": None,\n",
        "        \"report\": None,\n",
        "        \"confusion\": None,\n",
        "        \"roc_auc\": None,\n",
        "        \"pr_auc\": None\n",
        "    }\n",
        "\n",
        "    for thr in thresholds:\n",
        "        y_pred = (test_mse > thr).astype(int)\n",
        "\n",
        "        f1 = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
        "\n",
        "        if f1 > best[\"f1\"]:\n",
        "            prec = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
        "            rec  = recall_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
        "            best.update({\n",
        "                \"threshold\": thr,\n",
        "                \"f1\": f1,\n",
        "                \"precision\": prec,\n",
        "                \"recall\": rec,\n",
        "                \"report\": classification_report(y_test, y_pred, digits=4),\n",
        "                \"confusion\": confusion_matrix(y_test, y_pred)\n",
        "            })\n",
        "\n",
        "    # AUC-ROC e AUC-PR (não dependem de threshold)\n",
        "    try:\n",
        "        best[\"roc_auc\"] = roc_auc_score(y_test, test_mse)\n",
        "    except ValueError:\n",
        "        best[\"roc_auc\"] = np.nan\n",
        "\n",
        "    precision_curve, recall_curve, _ = precision_recall_curve(y_test, test_mse)\n",
        "    best[\"pr_auc\"] = auc(recall_curve, precision_curve)\n",
        "\n",
        "    return best\n",
        "\n",
        "\n",
        "def plot_confusion(cm, title):\n",
        "    labels = [\"Normal (0)\", \"Anômalo (1)\"]\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                                  display_labels=labels)\n",
        "    fig, ax = plt.subplots(figsize=(5,5))\n",
        "    disp.plot(cmap=\"Blues\", ax=ax, values_format=\"d\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Classe Predita\")\n",
        "    plt.ylabel(\"Classe Verdadeira\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Normalizada\n",
        "    cm_norm = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
        "    disp_norm = ConfusionMatrixDisplay(confusion_matrix=cm_norm,\n",
        "                                       display_labels=labels)\n",
        "    fig, ax = plt.subplots(figsize=(5,5))\n",
        "    disp_norm.plot(cmap=\"Blues\", ax=ax, values_format=\".2f\")\n",
        "    plt.title(title + \" (Normalizada)\")\n",
        "    plt.xlabel(\"Classe Predita\")\n",
        "    plt.ylabel(\"Classe Verdadeira\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_roc_pr(y_true, scores, model_name, roc_auc_val, pr_auc_val):\n",
        "    fpr, tpr, _ = roc_curve(y_true, scores)\n",
        "    precision_curve, recall_curve, _ = precision_recall_curve(y_true, scores)\n",
        "\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.plot([0,1], [0,1], linestyle=\"--\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(f\"{model_name} - ROC (AUC = {roc_auc_val:.3f})\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.plot(recall_curve, precision_curve)\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precisão\")\n",
        "    plt.title(f\"{model_name} - Precision-Recall (AUC = {pr_auc_val:.3f})\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 5. LSTM AUTOENCODER\n",
        "\n",
        "def build_lstm_autoencoder(timesteps, n_features):\n",
        "    inputs = layers.Input(shape=(timesteps, n_features))\n",
        "\n",
        "    # Encoder\n",
        "    x = layers.LSTM(64, return_sequences=True)(inputs)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.LSTM(32, return_sequences=False)(x)\n",
        "\n",
        "    # Latente repetido no tempo\n",
        "    encoded = layers.RepeatVector(timesteps)(x)\n",
        "\n",
        "    # Decoder\n",
        "    x = layers.LSTM(32, return_sequences=True)(encoded)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.LSTM(64, return_sequences=True)(x)\n",
        "    outputs = layers.TimeDistributed(layers.Dense(n_features))(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs, name=\"LSTM_AE\")\n",
        "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "lstm_ae = build_lstm_autoencoder(timesteps, n_features)\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-5\n",
        ")\n",
        "\n",
        "print(\"\\nTreinando LSTM-AE...\")\n",
        "history_lstm = lstm_ae.fit(\n",
        "    X_train,\n",
        "    X_train,\n",
        "    epochs=EPOCHS_LSTM,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    shuffle=True,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Avaliação LSTM-AE\n",
        "train_mse_lstm = reconstruction_mse(lstm_ae, X_train)\n",
        "test_mse_lstm  = reconstruction_mse(lstm_ae, X_test)\n",
        "\n",
        "# Visualização do MSE de treino (Q99)\n",
        "thr_lstm_q99 = np.quantile(train_mse_lstm, 0.99)\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(train_mse_lstm, bins=50)\n",
        "plt.axvline(thr_lstm_q99, color=\"r\", linestyle=\"--\", label=f\"Q99 = {thr_lstm_q99:.4e}\")\n",
        "plt.xlabel(\"MSE\")\n",
        "plt.ylabel(\"Frequência\")\n",
        "plt.title(\"LSTM-AE - MSE no treino (normal)\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "best_lstm = otimizar_threshold(train_mse_lstm, test_mse_lstm, y_test)\n",
        "\n",
        "print(\"\\n=== RESULTADOS LSTM-AE (threshold otimizado) ===\")\n",
        "print(f\"Threshold ótimo: {best_lstm['threshold']:.6e}\")\n",
        "print(f\"F1 (classe 1):   {best_lstm['f1']:.4f}\")\n",
        "print(f\"Precisão (1):    {best_lstm['precision']:.4f}\")\n",
        "print(f\"Recall (1):      {best_lstm['recall']:.4f}\")\n",
        "print(f\"AUC-ROC:         {best_lstm['roc_auc']:.4f}\")\n",
        "print(f\"AUC-PR:          {best_lstm['pr_auc']:.4f}\")\n",
        "print(\"\\nMatriz de confusão:\")\n",
        "print(best_lstm[\"confusion\"])\n",
        "print(\"\\nRelatório de classificação:\")\n",
        "print(best_lstm[\"report\"])\n",
        "\n",
        "plot_confusion(best_lstm[\"confusion\"], \"Matriz de Confusão - LSTM-AE\")\n",
        "plot_roc_pr(y_test, test_mse_lstm, \"LSTM-AE\",\n",
        "            best_lstm[\"roc_auc\"], best_lstm[\"pr_auc\"])\n",
        "\n",
        "# 6. VAE (VARIATIONAL AUTOENCODER)\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "# Encoder VAE\n",
        "encoder_inputs = layers.Input(shape=(timesteps, n_features))\n",
        "\n",
        "x = layers.LSTM(64, return_sequences=True)(encoder_inputs)\n",
        "x = layers.LSTM(32, return_sequences=False)(x)\n",
        "\n",
        "z_mean = layers.Dense(LATENT_DIM, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(LATENT_DIM, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "\n",
        "\n",
        "# Decoder VAE\n",
        "latent_inputs = layers.Input(shape=(LATENT_DIM,))\n",
        "x = layers.RepeatVector(timesteps)(latent_inputs)\n",
        "x = layers.LSTM(32, return_sequences=True)(x)\n",
        "x = layers.LSTM(64, return_sequences=True)(x)\n",
        "decoder_outputs = layers.TimeDistributed(layers.Dense(n_features))(x)\n",
        "\n",
        "decoder = models.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "\n",
        "\n",
        "class VAE(models.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            # reconstrução: MSE somado ao longo de tempo e features\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(tf.square(data - reconstruction), axis=(1,2))\n",
        "            )\n",
        "            kl_loss = -0.5 * tf.reduce_mean(\n",
        "                tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
        "            )\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "    def test_step(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "        z_mean, z_log_var, z = self.encoder(data)\n",
        "        reconstruction = self.decoder(z)\n",
        "        reconstruction_loss = tf.reduce_mean(\n",
        "            tf.reduce_sum(tf.square(data - reconstruction), axis=(1,2))\n",
        "        )\n",
        "        kl_loss = -0.5 * tf.reduce_mean(\n",
        "            tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
        "        )\n",
        "        total_loss = reconstruction_loss + kl_loss\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Para que vae(inputs) retorne a reconstrução e possamos usar reconstruction_mse\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        reconstruction = self.decoder(z)\n",
        "        return reconstruction\n",
        "\n",
        "\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=\"adam\")\n",
        "\n",
        "print(\"\\nTreinando VAE...\")\n",
        "history_vae = vae.fit(\n",
        "    X_train,\n",
        "    epochs=EPOCHS_VAE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    shuffle=True,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Avaliação VAE\n",
        "train_mse_vae = reconstruction_mse(vae, X_train)\n",
        "test_mse_vae  = reconstruction_mse(vae, X_test)\n",
        "\n",
        "thr_vae_q99 = np.quantile(train_mse_vae, 0.99)\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(train_mse_vae, bins=50)\n",
        "plt.axvline(thr_vae_q99, color=\"r\", linestyle=\"--\", label=f\"Q99 = {thr_vae_q99:.4e}\")\n",
        "plt.xlabel(\"MSE\")\n",
        "plt.ylabel(\"Frequência\")\n",
        "plt.title(\"VAE - MSE no treino (normal)\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"lstm_ae_mse_treino.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "best_vae = otimizar_threshold(train_mse_vae, test_mse_vae, y_test)\n",
        "\n",
        "print(\"\\n=== RESULTADOS VAE (threshold otimizado) ===\")\n",
        "print(f\"Threshold ótimo: {best_vae['threshold']:.6e}\")\n",
        "print(f\"F1 (classe 1):   {best_vae['f1']:.4f}\")\n",
        "print(f\"Precisão (1):    {best_vae['precision']:.4f}\")\n",
        "print(f\"Recall (1):      {best_vae['recall']:.4f}\")\n",
        "print(f\"AUC-ROC:         {best_vae['roc_auc']:.4f}\")\n",
        "print(f\"AUC-PR:          {best_vae['pr_auc']:.4f}\")\n",
        "print(\"\\nMatriz de confusão:\")\n",
        "print(best_vae[\"confusion\"])\n",
        "print(\"\\nRelatório de classificação:\")\n",
        "print(best_vae[\"report\"])\n",
        "\n",
        "plot_confusion(best_vae[\"confusion\"], \"Matriz de Confusão - VAE\")\n",
        "plot_roc_pr(y_test, test_mse_vae, \"VAE\",\n",
        "            best_vae[\"roc_auc\"], best_vae[\"pr_auc\"])\n",
        "\n",
        "# 7. TABELA RESUMO LSTM-AE vs VAE\n",
        "\n",
        "resumo = pd.DataFrame({\n",
        "    \"modelo\":   [\"LSTM-AE\", \"VAE\"],\n",
        "    \"threshold\": [best_lstm[\"threshold\"], best_vae[\"threshold\"]],\n",
        "    \"F1\":       [best_lstm[\"f1\"],        best_vae[\"f1\"]],\n",
        "    \"precisao\": [best_lstm[\"precision\"], best_vae[\"precision\"]],\n",
        "    \"recall\":   [best_lstm[\"recall\"],    best_vae[\"recall\"]],\n",
        "    \"AUC_ROC\":  [best_lstm[\"roc_auc\"],   best_vae[\"roc_auc\"]],\n",
        "    \"AUC_PR\":   [best_lstm[\"pr_auc\"],    best_vae[\"pr_auc\"]],\n",
        "})\n",
        "\n",
        "def mse_por_classe(test_mse, y_true):\n",
        "    return test_mse[y_true == 0].mean(), test_mse[y_true == 1].mean()\n",
        "\n",
        "mse_norm_lstm, mse_anom_lstm = mse_por_classe(test_mse_lstm, y_test)\n",
        "mse_norm_vae,  mse_anom_vae  = mse_por_classe(test_mse_vae,  y_test)\n",
        "\n",
        "mse_resumo = pd.DataFrame({\n",
        "    \"modelo\":      [\"LSTM-AE\", \"VAE\"],\n",
        "    \"MSE_normal\":  [mse_norm_lstm, mse_norm_vae],\n",
        "    \"MSE_anomalo\": [mse_anom_lstm, mse_anom_vae],\n",
        "})\n",
        "\n",
        "print(\"\\n=== RESUMO MÉTRICAS (LSTM-AE vs VAE, threshold otimizado) ===\")\n",
        "print(resumo.to_string(index=False))\n",
        "\n",
        "print(\"\\n=== MSE médio por classe (LSTM-AE vs VAE) ===\")\n",
        "print(mse_resumo.to_string(index=False))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
